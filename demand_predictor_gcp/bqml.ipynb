{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10dcdf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.3.4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from utils import get_daily_demand_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b872df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery==1.25.0\n",
      "  Downloading google_cloud_bigquery-1.25.0-py2.py3-none-any.whl (169 kB)\n",
      "\u001b[K     |████████████████████████████████| 169 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-resumable-media<0.6dev,>=0.5.0\n",
      "  Downloading google_resumable_media-0.5.1-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (3.16.0)\n",
      "Requirement already satisfied: google-api-core<2.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.31.1)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.34.0)\n",
      "Requirement already satisfied: six<2.0.0dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.16.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.25.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (21.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.53.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (57.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.2.7)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.5.30)\n",
      "Installing collected packages: google-resumable-media, google-cloud-bigquery\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-storage 1.42.0 requires google-resumable-media<3.0dev,>=1.3.0; python_version >= \"3.6\", but you have google-resumable-media 0.5.1 which is incompatible.\u001b[0m\n",
      "Successfully installed google-cloud-bigquery-1.25.0 google-resumable-media-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user google-cloud-bigquery==1.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0546ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change with your own bucket and project below:\n",
    "BUCKET =  \"qwiklabs-gcp-02-68978b5afbca\"\n",
    "PROJECT = \"qwiklabs-gcp-02-68978b5afbca\"\n",
    "\n",
    "OUTDIR = \"gs://{bucket}/demand/data\".format(bucket=BUCKET)\n",
    "\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['OUTDIR'] = OUTDIR\n",
    "os.environ['PROJECT'] = PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8eabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-04-01'\n",
    "end_date = '2020-03-31' \n",
    "\n",
    "NORM_VALUE = 1e6 # divided all values normalization\n",
    "\n",
    "values, times = get_daily_demand_data(start_date, end_date, write_json=False)\n",
    "values = values / NORM_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4058abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'times': times, 'values': values})\n",
    "dataset.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "817f0b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/dataset.csv [Content-Type=text/csv]...\n",
      "Copying file://data/data.json [Content-Type=application/json]...                \n",
      "Copying file://data/.ipynb_checkpoints/dataset-checkpoint.csv [Content-Type=text/csv]...\n",
      "/ [3 files][ 48.8 KiB/ 48.8 KiB]                                                \n",
      "Operation completed over 3 objects/48.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r data gs://qwiklabs-gcp-02-68978b5afbca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71bb9d",
   "metadata": {},
   "source": [
    "## Create BQ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db322e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/feature_engineering/labs/1_bqml_basic_feat_eng_bqml-lab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb541d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BigQuery dataset\n",
      "Dataset 'qwiklabs-gcp-02-68978b5afbca:demand_pred' successfully created.\n",
      "\\nHere are your current datasets:\n",
      "   datasetId   \n",
      " ------------- \n",
      "  demand_pred  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Create a BigQuery dataset\n",
    "\n",
    "datasetexists=$(bq ls -d | grep -w demand_pred)\n",
    "\n",
    "if [ -n \"$datasetexists\" ]; then\n",
    "    echo -e \"BigQuery dataset already exists, let's not recreate it.\"\n",
    "\n",
    "else\n",
    "    echo \"Creating BigQuery dataset\"\n",
    "    \n",
    "    bq --location=US mk --dataset \\\n",
    "        --description 'Demand prediction' \\\n",
    "        $PROJECT:demand_pred\n",
    "   echo \"Here are your current datasets:\"\n",
    "   bq ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6157f2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload complete.\n",
      "Waiting on bqjob_r4868e967e97a7586_0000017bb0e0dd5a_1 ... (1s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "bq load --autodetect \\\n",
    "        --location=US \\\n",
    "        --source_format=CSV \\\n",
    "        qwiklabs-gcp-02-68978b5afbca:demand_pred.mytable \\\n",
    "        dataset.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "294889b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 314.72query/s]                          \n",
      "Downloading: 100%|██████████| 366/366 [00:01<00:00, 231.92rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.728854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>0.740720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>0.743726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>0.746532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>0.758884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>0.667336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>0.605617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>0.540515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>0.610996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>0.585077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          times    values\n",
       "0    2019-04-01  0.728854\n",
       "1    2019-04-02  0.740720\n",
       "2    2019-04-03  0.743726\n",
       "3    2019-04-04  0.746532\n",
       "4    2019-04-05  0.758884\n",
       "..          ...       ...\n",
       "361  2020-03-27  0.667336\n",
       "362  2020-03-28  0.605617\n",
       "363  2020-03-29  0.540515\n",
       "364  2020-03-30  0.610996\n",
       "365  2020-03-31  0.585077\n",
       "\n",
       "[366 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    " \n",
    "SELECT times, values\n",
    "FROM\n",
    "  demand_pred.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7486f",
   "metadata": {},
   "source": [
    "## Create Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1271bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL\n",
    "  feat_eng.baseline_model OPTIONS (model_type='linear_reg',\n",
    "    input_label_cols=['fare_amount']) AS\n",
    "SELECT\n",
    "  fare_amount,\n",
    "  passengers,\n",
    "  pickup_datetime,\n",
    "  pickuplon,\n",
    "  pickuplat,\n",
    "  dropofflon,\n",
    "  dropofflat\n",
    "FROM\n",
    "  feat_eng.feateng_training_data"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-3.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-3:m78"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
