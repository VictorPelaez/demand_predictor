{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3733888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from utils import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ffa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"data/dataset.csv\")\n",
    "eval_dataset = pd.read_csv(\"data/dataset_eval.csv\")\n",
    "\n",
    "time_train = np.array(train_dataset.times)\n",
    "x_train = np.array(train_dataset.values)[:,1].astype('float32')\n",
    "\n",
    "time_eval = np.array(eval_dataset.times)\n",
    "x_eval = np.array(eval_dataset.values)[:,1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31083b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "  \"\"\"\n",
    "    Description:  \n",
    "    Input: \n",
    "      - series:\n",
    "      - window_size:\n",
    "      - batch_size: the batches to use when training\n",
    "      -shuffle_buffer: size buffer, how data will be shuffled\n",
    "\n",
    "    Output:\n",
    "\n",
    "  \"\"\"\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1])) # x and y (last one)\n",
    "  dataset = dataset.batch(batch_size).prefetch(1)\n",
    "  return dataset\n",
    "\n",
    "window_size = 30\n",
    "batch_size = 16\n",
    "shuffle_buffer_size = 100\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)\n",
    "\n",
    "train_set = windowed_dataset(x_train, window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense NN\n",
    "\n",
    "EPOCHS = 1000\n",
    "LR = 1e-3\n",
    "\n",
    "l0 = tf.keras.layers.Dense(2*window_size+1, input_shape=[window_size], activation='relu')\n",
    "l2 = tf.keras.layers.Dense(1)\n",
    "model = tf.keras.models.Sequential([l0, l2])\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-3)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr=LR, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=['mae'])\n",
    "history = model.fit(train_set, epochs=EPOCHS, verbose=0)\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot Loss\n",
    "#------------------------------------------------\n",
    "loss=history.history['loss']\n",
    "epochs_=range(len(loss)) # Get number of epochs\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs_, loss, 'b')\n",
    "plt.title('Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "n_epochs = 2000\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs_[n_epochs:], loss[n_epochs:], 'b')\n",
    "plt.title('zoom Loss')\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "# Forecasting and evaluation\n",
    "#------------------------------------------------\n",
    "\n",
    "eval_dataset = windowed_dataset(x_eval, window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n",
    "result = np.array(model.predict(eval_dataset))[:, 0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_eval[window_size:], x_eval[window_size:], format='-o')\n",
    "plot_series(time_eval[window_size:], results, format='-o')\n",
    "\n",
    "print(tf.keras.metrics.mean_absolute_error(x_eval[window_size:], results).numpy())    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
